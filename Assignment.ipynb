{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled38.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fce81956018c4f189711630b41d4c64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_194f462a99bd44cca7d96a512aae2f64",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e8a43f2482264f9a88c90781be685c1c",
              "IPY_MODEL_5880b1ec538e4645a09dce7f9e118c88",
              "IPY_MODEL_4b36dca5b4d441478480613f1c3510d1"
            ]
          }
        },
        "194f462a99bd44cca7d96a512aae2f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8a43f2482264f9a88c90781be685c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58b2c2b3c9264bd49172bc08c799a3e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ab70e42bd1b4c5799a883e747067bca"
          }
        },
        "5880b1ec538e4645a09dce7f9e118c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbfef9cc52654c68ac6672c7331fe89e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 26421880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26421880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fae834ea158541e9893ac6e30f02b7d0"
          }
        },
        "4b36dca5b4d441478480613f1c3510d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c97dc794739b4f60ac374047a71778e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26422272/? [00:01&lt;00:00, 24293995.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cfd40b54f8847588d981c511b706f30"
          }
        },
        "58b2c2b3c9264bd49172bc08c799a3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ab70e42bd1b4c5799a883e747067bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbfef9cc52654c68ac6672c7331fe89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fae834ea158541e9893ac6e30f02b7d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c97dc794739b4f60ac374047a71778e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cfd40b54f8847588d981c511b706f30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nageswar-Sahoo/PyTorch_101/blob/main/Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mylHpMHEmXtL",
        "outputId": "76cdc7a1-9f07-4ec5-82b5-9d94d2de73b5"
      },
      "source": [
        "# Pytorch's tensors are similar to Numpy's ndarrays  Python Upodated Nageshwar \n",
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DgpGnurm3GT"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch \n",
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467,
          "referenced_widgets": [
            "fce81956018c4f189711630b41d4c64a",
            "194f462a99bd44cca7d96a512aae2f64",
            "e8a43f2482264f9a88c90781be685c1c",
            "5880b1ec538e4645a09dce7f9e118c88",
            "4b36dca5b4d441478480613f1c3510d1",
            "58b2c2b3c9264bd49172bc08c799a3e1",
            "3ab70e42bd1b4c5799a883e747067bca",
            "fbfef9cc52654c68ac6672c7331fe89e",
            "fae834ea158541e9893ac6e30f02b7d0",
            "c97dc794739b4f60ac374047a71778e0",
            "3cfd40b54f8847588d981c511b706f30",
            "22fd5da9824143f4a5f1fab795b156c2",
            "3b124a2d47534cb6a96d91fda19fe29f",
            "92b8aad1c2744a5a926879f3f8f4f90a"
          ]
        },
        "id": "_h0rpRWvmqHE",
        "outputId": "5d914d72-c7c9-42db-d3ee-69abe1623374"
      },
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.Compose([\n",
        "          transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fce81956018c4f189711630b41d4c64a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/26421880 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22fd5da9824143f4a5f1fab795b156c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/29515 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b124a2d47534cb6a96d91fda19fe29f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4422102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92b8aad1c2744a5a926879f3f8f4f90a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/5148 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHXuBlld5_Om"
      },
      "source": [
        "def getRandomNumber(batchsize):\n",
        "  return random.sample(range(0, 10), batchsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJQiUPoIMUY3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-l1KRGbm34R"
      },
      "source": [
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) \n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=232, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=29)\n",
        "\n",
        "    self.fcr1 = nn.Linear(in_features=10, out_features=20)\n",
        "    self.fcr2 = nn.Linear(in_features=20, out_features=40)\n",
        "  \n",
        "  def forward(self, t, randomNum):\n",
        "    # input layer\n",
        "    x = t\n",
        "    y=randomNum\n",
        "\n",
        "\n",
        "    # conv1 layer\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) # 28 | 24 | 12\n",
        "\n",
        "    # conv2 layer\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) # 12 | 8 | 4 >> 12x4x4\n",
        "\n",
        "    # reshapre\n",
        "    x = x.reshape(-1, 12 * 4 * 4)\n",
        "    y = y.reshape(-1, 10)\n",
        "\n",
        "    #print(x.shape)\n",
        "    #print(y.shape)\n",
        "\n",
        "    # fcr layer\n",
        "    y = self.fcr1(y)\n",
        "    y = F.relu(y)\n",
        "\n",
        "\n",
        "    # fcr layer\n",
        "    y = self.fcr2(y)\n",
        "    y = F.relu(y)\n",
        "\n",
        "\n",
        "    #print(\"Before concat\")\n",
        "    #print(x.shape)\n",
        "    #print(y.shape)\n",
        "\n",
        "    x=torch.cat((x,y ), 1)\n",
        "\n",
        "    #print(\"Shape After concat \")\n",
        "    #print(x.shape)\n",
        "\n",
        "\n",
        "    # fc1 layer\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # fc2 layer\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # output layer\n",
        "    x = self.out(x)\n",
        "    # x = F.softmax(x, dim=1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkguMqE8m8nU"
      },
      "source": [
        "network = Network()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIcFPxRv0aED"
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "5Udv8hPj0ir7",
        "outputId": "d5dd705b-04e0-4705-ed79-52fadadbfaa7"
      },
      "source": [
        "summary(network, [(1,28,28),(1,10)])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 24, 24]             156\n",
            "            Conv2d-2             [-1, 12, 8, 8]           1,812\n",
            "            Linear-3                   [-1, 20]             220\n",
            "            Linear-4                   [-1, 40]             840\n",
            "            Linear-5                  [-1, 120]          27,960\n",
            "            Linear-6                   [-1, 60]           7,260\n",
            "            Linear-7                   [-1, 29]           1,769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c5f298f86f40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# assume 4 bytes/number (float on cuda).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mtotal_input_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mtotal_output_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_output\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# x2 for gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mtotal_params_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2998\u001b[0m     \"\"\"\n\u001b[1;32m   2999\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0;32m-> 3000\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   3001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'tuple'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fydt4PIRoDSx"
      },
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySmpdR0U6b3Z",
        "outputId": "78ab05ca-d5ac-484c-f349-f4efac979d71"
      },
      "source": [
        "getRandomNumber(batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 5, 8, 0, 4, 3, 1, 6, 7, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dBaDy-lBV2c"
      },
      "source": [
        "def getSum(list1,list2):\n",
        "    return [x + y for (x, y) in zip(labels, randomNum)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M59oYOW3BeIA"
      },
      "source": [
        "torch.stack((t1,t2),dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "1EfUETwNnPWc",
        "outputId": "82f45272-2913-4ca1-bdb3-0e09872077ed"
      },
      "source": [
        "batch_size=10\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size)\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
        "sigmoid = nn.Sigmoid() # initialize sigmoid layer\n",
        "lossCal = nn.BCEWithLogitsLoss() # initialize loss function\n",
        "\n",
        "for epoch in range(1):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for batch in train_loader: # Get Batch\n",
        "        images, labels = batch \n",
        "        #print(\"One hot \")\n",
        "        randomNum=getRandomNumber(batch_size)\n",
        "\n",
        "        randomNumTensor = torch.as_tensor(randomNum)    \n",
        "        res=torch.cat((F.one_hot(labels, num_classes=10), F.one_hot(randomNumTensor, num_classes=19)), 1)\n",
        "        #print(randomNumTensor)\n",
        "        #print(res)\n",
        "        #print(labels)\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        preds = network(images,torch.as_tensor(F.one_hot(randomNumTensor, num_classes=10) , dtype=torch.float)) # Pass Batch\n",
        "        print(\"After Prediction\")\n",
        "        #print(res.type(torch.float))\n",
        "        #print(sigmoid(preds))\n",
        "        #print(res)\n",
        "        b=res.type(torch.float)         \n",
        "                \n",
        "        #loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
        "        loss = lossCal(preds, b) # Calculate Loss\n",
        "\n",
        "        \n",
        "      \n",
        "        #print(preds)\n",
        "        #print(preds[:,0:10])\n",
        "        print(preds[:,10:])\n",
        "        #print(\"ARGMAX\")\n",
        "        #print(preds[:,0:10].argmax(dim=1))\n",
        "        print(preds[:,10:].argmax(dim=1))\n",
        "\n",
        "        #print(\"Actual Label\")\n",
        "        #print(labels)\n",
        "        #print(randomNumTensor+labels)\n",
        "        #print(\"H2\")\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() # Calculate Gradients\n",
        "        optimizer.step() # Update Weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += get_num_correct(preds, labels)\n",
        "        break\n",
        "\n",
        "    print(\n",
        "        \"epoch\", epoch, \n",
        "        \"total_correct:\", total_correct, \n",
        "        \"loss:\", total_loss\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Prediction\n",
            "tensor([[-0.0157, -0.0581,  0.0427, -0.1088, -0.1180,  0.0925, -0.1188, -0.1093,\n",
            "         -0.0489, -0.0683,  0.0252, -0.0711,  0.0197, -0.0856,  0.0713,  0.1718,\n",
            "         -0.1030,  0.1284, -0.1436],\n",
            "        [-0.0138, -0.0551,  0.0442, -0.1190, -0.1183,  0.1068, -0.1347, -0.1215,\n",
            "         -0.0411, -0.0687,  0.0180, -0.0679,  0.0138, -0.0847,  0.0639,  0.1584,\n",
            "         -0.1102,  0.1299, -0.1420],\n",
            "        [-0.0101, -0.0511,  0.0391, -0.1140, -0.1247,  0.1040, -0.1176, -0.1142,\n",
            "         -0.0565, -0.0586,  0.0095, -0.0513,  0.0206, -0.0785,  0.0652,  0.1580,\n",
            "         -0.1050,  0.1175, -0.1389],\n",
            "        [-0.0071, -0.0532,  0.0437, -0.1067, -0.1193,  0.1038, -0.1181, -0.1106,\n",
            "         -0.0545, -0.0620,  0.0159, -0.0556,  0.0157, -0.0770,  0.0658,  0.1614,\n",
            "         -0.1080,  0.1228, -0.1426],\n",
            "        [-0.0100, -0.0539,  0.0496, -0.1098, -0.1213,  0.0957, -0.1258, -0.1079,\n",
            "         -0.0501, -0.0771,  0.0251, -0.0642,  0.0208, -0.0770,  0.0724,  0.1658,\n",
            "         -0.1143,  0.1310, -0.1443],\n",
            "        [-0.0112, -0.0484,  0.0411, -0.1128, -0.1179,  0.1057, -0.1227, -0.1202,\n",
            "         -0.0458, -0.0668,  0.0156, -0.0604,  0.0186, -0.0820,  0.0618,  0.1659,\n",
            "         -0.1094,  0.1225, -0.1465],\n",
            "        [-0.0109, -0.0564,  0.0341, -0.0995, -0.1150,  0.1049, -0.1218, -0.1154,\n",
            "         -0.0571, -0.0557,  0.0080, -0.0539,  0.0126, -0.0802,  0.0682,  0.1562,\n",
            "         -0.1031,  0.1175, -0.1419],\n",
            "        [-0.0116, -0.0477,  0.0401, -0.1133, -0.1222,  0.1050, -0.1215, -0.1147,\n",
            "         -0.0432, -0.0586,  0.0240, -0.0677,  0.0170, -0.0807,  0.0568,  0.1676,\n",
            "         -0.1064,  0.1258, -0.1397],\n",
            "        [-0.0072, -0.0528,  0.0401, -0.1066, -0.1189,  0.1028, -0.1137, -0.1092,\n",
            "         -0.0578, -0.0539,  0.0124, -0.0541,  0.0220, -0.0825,  0.0667,  0.1593,\n",
            "         -0.1022,  0.1156, -0.1425],\n",
            "        [-0.0089, -0.0576,  0.0445, -0.1072, -0.1178,  0.1002, -0.1161, -0.1131,\n",
            "         -0.0433, -0.0598,  0.0216, -0.0712,  0.0226, -0.0893,  0.0665,  0.1702,\n",
            "         -0.1081,  0.1236, -0.1434]], grad_fn=<SliceBackward>)\n",
            "tensor([15, 15, 15, 15, 15, 15, 15, 15, 15, 15])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-361c47d91139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtotal_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_num_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_num_correct' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz_4Qjuy4mQl"
      },
      "source": [
        "x = torch.randn(10, 5)\n",
        "y = torch.randint(5, (10,))\n",
        "loss = nn.CrossEntropyLoss()(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrX9zHry4nVT",
        "outputId": "094f3f3a-3f34-4777-b0f8-81c0e36490e9"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.5424,  0.1245,  0.8532, -0.0406,  1.9486],\n",
              "        [ 0.3504, -1.0312,  2.5902, -1.6936,  0.3229],\n",
              "        [ 1.2855,  0.1325, -0.4814, -0.8483, -0.9243],\n",
              "        [-0.6925, -0.3340, -1.0145, -0.5652,  0.3913],\n",
              "        [ 0.3336,  0.6916, -1.0933, -0.2525, -1.3558],\n",
              "        [-1.8370,  1.1006, -0.0550, -1.0756, -0.7686],\n",
              "        [ 1.0511,  1.7066, -0.0846,  0.3604, -0.9002],\n",
              "        [ 1.8079,  0.5024,  1.4377, -1.9466, -0.2282],\n",
              "        [-2.7253,  0.0736,  0.1742, -0.0887, -0.5566],\n",
              "        [-0.8521,  0.6604, -2.1746, -0.8742,  0.3429]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z6wH1Mh4t5-",
        "outputId": "c43a933b-01f1-4a78-f356-c267f8c31dc9"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 2, 3, 3, 4, 1, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7i2yccWuWoJ"
      },
      "source": [
        "\n",
        "#https://learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/\n",
        "criterion = nn.BCELoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IULz0s9Jm-9n",
        "outputId": "b9b1de81-2924-4925-aaf8-d73d681ee4c7"
      },
      "source": [
        "def forward(self, x):\n",
        "    # Do your stuff here\n",
        "    ...\n",
        "    x1 = F.log_softmax(x) # class probabilities\n",
        "    x2 = ... # bounding box calculation\n",
        "    return x1, x2\n",
        "\n",
        "\n",
        "\n",
        "out1, out2 = model(data)\n",
        "loss1 = criterion1(out1, target1)\n",
        "loss2 = criterion2(out2, target2)\n",
        "loss = loss1 + loss2\n",
        "loss.backward()    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  tensor([[ 1.3642,  1.0437,  1.0348, -0.9041, -0.1930],\n",
            "        [-1.2949, -2.2943,  0.0463,  0.5318, -0.2117]], requires_grad=True)\n",
            "target:  tensor([0, 4])\n",
            "output:  tensor(1.2981, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RIsxcZVnwvZ"
      },
      "source": [
        "list1=[[ 1.3642,  1.0437,  1.0348 ],\n",
        "        [-1.2949, -2.2943,  0.0463,  0.5318, -0.2117, -0.9041, -0.1930]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF4ldoLmn7Ye",
        "outputId": "bf743564-641b-4790-b031-acb1aa72551a"
      },
      "source": [
        "list1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.3642, 1.0437, 1.0348, -0.9041, -0.193],\n",
              " [-1.2949, -2.2943, 0.0463, 0.5318, -0.2117]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsn7CqPNwHse"
      },
      "source": [
        "\n",
        "input = torch.randn(3, requires_grad=True) # give some random input\n",
        "target = torch.empty(3).random_(2) # create some ground truth values\n",
        "output = loss(m(input), target) # forward pass\n",
        "output.backward() # backward pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaF0oMXrwQPy",
        "outputId": "7ecfea20-3a96-41a7-f3d7-20d142dac8ed"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDIeYvSUwJxR",
        "outputId": "c60d2695-368a-4d57-91ac-782acbf8e23b"
      },
      "source": [
        "input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7451, -0.2807,  0.9495], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtCo_VlMwLO3",
        "outputId": "59887d48-28b4-4877-9bd3-cec9f8c8abc5"
      },
      "source": [
        "target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFu4P6XC2N8Z",
        "outputId": "659518c8-1037-4474-d329-b0a6bf02798f"
      },
      "source": [
        "import random\n",
        "#Generate 5 random numbers between 10 and 30\n",
        "randomlist1 = random.sample(range(0, 10), 5)\n",
        "randomlist2 = random.sample(range(0, 10), 6)\n",
        "randomlist3 = random.sample(range(0, 10), 7)\n",
        "randomlist4 = random.sample(range(0, 10), 8)\n",
        "print(randomlist1)\n",
        "print(randomlist2)\n",
        "print(randomlist3)\n",
        "print(randomlist4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7, 8, 4, 2, 5]\n",
            "[7, 6, 5, 9, 1, 4]\n",
            "[3, 9, 6, 4, 7, 1, 8]\n",
            "[1, 7, 4, 2, 6, 8, 5, 0]\n"
          ]
        }
      ]
    }
  ]
}